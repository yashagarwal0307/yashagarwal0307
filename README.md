# 👋 Hi, I'm Yash Agarwal

I'm a Aspiring Ai/ML engineer with an MSc in Data Science from the Defence Institute of Advanced Technology. I'm deeply passionate about Generative AI and Multimodal AI, and I love building machine learning solutions that solve real-world problems.


---

## 🔍 About Me

- 🎓 MSc in Data Science — Defence Institute of Advanced Technology  
- 🧪 Research Intern — Jadavpur University  
- 🧠 Passionate about GenAI, Multimodal AI, Computer Vision, NLP, and LLMs  
- 💡 I believe in practical ML/DL applications that create real impact  

---

## 💻 Tech Stack

**Languages & Frameworks**  
`Python`, `Scikit-learn`, `TensorFlow`, `PyTorch`

**Data & Visualization**  
`Pandas`, `NumPy`, `Matplotlib`, `Seaborn`

**Natural Language & Computer Vision**  
`NLTK`, `Hugging Face Transformers`, `OpenCV`

**Generative AI & Deployment**  
`LangChain`, `Streamlit`, `Transformers`

---

## 🚀 Featured Projects

### 🔐 Face Recognition and Gender Classification – COMFSYS Hackathon  
🔹 Task A – Gender Classification
-Handled class imbalance with upsampling and extracted features using EfficientNet-B3.
-Combined Random Forest, XGBoost, and CatBoost in a Voting Classifier.
-Achieved a solid 93.8% validation accuracy on challenging data.

🔹 Task B – Face Recognition
-Built a Siamese Network trained with Triplet Loss to learn identity-aware embeddings.
-Used MobileNetV2 to generate 128-D face vectors, evaluated via cosine similarity.
-Delivered a 98.25% Top-1 Accuracy, proving robust recognition performance. 

### 🚌 Bus Demand Prediction – Redbus Hackathon  

-Performed EDA to identify trends in booking behavior — higher demand on weekends, holidays, and close to travel dates.
-Hand-crafted features like tier combinations and adjusted seat availability for holidays and weekends.
-Trained models including TabularNet (AutoGluon) and Random Forest Regressor for demand prediction.
-TabularNet and Random Forest gave the best results, capturing demand patterns across routes and dates.  

### 💬 Product Sentiment Analysis with BERT  
- Fine-tuned a BERT-base-uncased model to classify tweets into positive, negative, or neutral sentiment.
- Tackled class imbalance with text augmentation (synonym replacement via nlpaug), boosting per-class F1 scores.
- Achieved ~85% accuracy and 84.6 F1 score, using macro and weighted F1 for balanced evaluation.
- Deployed a Streamlit UI for real-time sentiment prediction using the fine-tuned model
  
### 🔆 Solar Efficiency Prediction(Zelestra X AWS ML Ascend Challenge)
 - Applied Mutual Information, Pearson Correlation, and VIF for effective feature selection.
 - Trained multiple models including XGBoost, CatBoost, SVR, Random Forest, and ELM.
 - Combined top models using a Voting Regressor to enhance prediction stability.
 - Achieved a validation score of 89.79 in the Zelestra X AWS ML Ascend Challenge.
---

## 📬 Connect with Me

- 💼 LinkedIn-https://www.linkedin.com/in/yash-agarwal-20424b1b3/  
- 📧 Email: yashaimldl@gmail.com
---

Thanks for stopping by!


